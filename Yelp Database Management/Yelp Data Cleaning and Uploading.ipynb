{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdG4oHinzKom"
      },
      "source": [
        "Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "U2LyxEMryfJl",
        "outputId": "0c44dc1c-96c3-4bbd-bfd9-6c7fb67bebdb"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2219701020.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json'"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"badm-554-mini-project-1-group-3.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1rrTIHXoZD8P1y8tPE6mrkn4_T1KFTsiv\n",
        "\"\"\"\n",
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "\n",
        "data_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json\")\n",
        "data = []\n",
        "for line in data_file:\n",
        "    data.append(json.loads(line))\n",
        "review_df = pd.DataFrame(data)\n",
        "data_file.close()\n",
        "\n",
        "review_df[['date', 'time']] = review_df['date'].str.split(' ', expand=True)\n",
        "\n",
        "review_df['date'] = pd.to_datetime(review_df['date'])\n",
        "review_df['time'] = pd.to_datetime(review_df['time'],format='%H:%M:%S')\n",
        "\n",
        "review_df\n",
        "#linked to user and business table through user_id and business_id\n",
        "\n",
        "data_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_checkin.json\")\n",
        "data = []\n",
        "for line in data_file:\n",
        "    data.append(json.loads(line))\n",
        "checkin_df = pd.DataFrame(data)\n",
        "data_file.close()\n",
        "\n",
        "checkin_df[\"date\"] = checkin_df[\"date\"].str.split(\", \")\n",
        "checkin_df_exploded = checkin_df.explode(\"date\", ignore_index = True)\n",
        "checkin_df_exploded.insert(0, \"checkin_id\", range(1, len(checkin_df_exploded) + 1))\n",
        "\n",
        "checkin_df_exploded['date'] = pd.to_datetime(checkin_df_exploded['date'])\n",
        "\n",
        "checkin_df_exploded\n",
        "\n",
        "checkin_df_exploded.dtypes\n",
        "\n",
        "data_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_business.json\")\n",
        "data = []\n",
        "for line in data_file:\n",
        "    data.append(json.loads(line))\n",
        "business_df = pd.DataFrame(data)\n",
        "data_file.close()\n",
        "\n",
        "business_df.drop(['review_count','stars'],axis=1,inplace=True)\n",
        "\n",
        "business_df = pd.concat([business_df.drop(columns=['hours']), pd.json_normalize(business_df['hours'])], axis=1)\n",
        "\n",
        "business_df = business_df.rename(columns={'Monday':'monday_hours','Tuesday':'tuesday_hours','Wednesday':'wednesday_hours','Thursday':'thursday_hours','Friday':'friday_hours','Saturday':'saturday_hours','Sunday':'sunday_hours'})\n",
        "\n",
        "business_df\n",
        "\n",
        "records = []\n",
        "\n",
        "for _, row in business_df.iterrows():\n",
        "    business_id = row['business_id']\n",
        "    attrs = row['attributes']\n",
        "\n",
        "    if not isinstance(attrs, dict):\n",
        "        continue\n",
        "\n",
        "    for key, val in attrs.items():\n",
        "        # Store raw text form (keep nested dicts as-is)\n",
        "        records.append({\n",
        "            'business_id': business_id,\n",
        "            'attribute_name': key,\n",
        "            'attribute_value': str(val)  # store everything as text\n",
        "        })\n",
        "\n",
        "business_attributes = pd.DataFrame(records)\n",
        "\n",
        "business_attributes\n",
        "\n",
        "business_df.drop('attributes',axis=1,inplace=True)\n",
        "\n",
        "data_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_tip.json\")\n",
        "data = []\n",
        "for line in data_file:\n",
        "    data.append(json.loads(line))\n",
        "tip_df = pd.DataFrame(data)\n",
        "data_file.close()\n",
        "\n",
        "tip_df\n",
        "#linked to user and business table through user_id and business_id\n",
        "\n",
        "tip_df_cleaned = tip_df[['user_id','business_id','text','date']]\n",
        "\n",
        "tip_df_cleaned['date'] = pd.to_datetime(tip_df_cleaned['date'])\n",
        "\n",
        "tip_df_cleaned\n",
        "\n",
        "data_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_user.json\")\n",
        "data = []\n",
        "for line in data_file:\n",
        "    data.append(json.loads(line))\n",
        "user_df = pd.DataFrame(data)\n",
        "data_file.close()\n",
        "\n",
        "user_df.columns\n",
        "\n",
        "user_df.drop(['review_count','average_stars'],axis=1,inplace=True)\n",
        "\n",
        "review_df\n",
        "\n",
        "checkin_df_exploded\n",
        "\n",
        "business_df\n",
        "\n",
        "business_categories_df = business_df[['business_id','categories']]\n",
        "\n",
        "business_categories_df\n",
        "\n",
        "business_categories_df[\"categories\"] = business_categories_df[\"categories\"].str.split(\", \")\n",
        "business_categories_df_exploded = business_categories_df.explode(\"categories\", ignore_index = True)\n",
        "business_categories_df_exploded.insert(0, \"category_id\", range(1, len(business_categories_df_exploded) + 1))\n",
        "\n",
        "business_categories_df_exploded\n",
        "\n",
        "business_attributes\n",
        "\n",
        "business_attributes.insert(0, \"attribute_id\", range(1, len(business_attributes) + 1))\n",
        "\n",
        "business_attributes\n",
        "\n",
        "tip_df_cleaned\n",
        "\n",
        "tip_df_cleaned.insert(0, \"tip_id\", range(1, len(tip_df_cleaned) + 1))\n",
        "\n",
        "tip_df_cleaned\n",
        "\n",
        "tip_df_cleaned.dtypes\n",
        "\n",
        "user_df\n",
        "\n",
        "user_df[user_df['elite'] == '20,20,2021']\n",
        "#data seems to be incorrectly formatted in the elite column. 2020 may be inputted as 20,20\n",
        "\n",
        "user_df['elite'] = user_df['elite'].str.replace('20,20','2020')\n",
        "\n",
        "user_df['elite'].value_counts()\n",
        "\n",
        "elite_years_df = user_df[['user_id','elite']]\n",
        "\n",
        "elite_years_df\n",
        "\n",
        "elite_years_df[\"elite\"] = elite_years_df[\"elite\"].str.split(\",\")\n",
        "elite_years_df_exploded = elite_years_df.explode(\"elite\", ignore_index = True)\n",
        "elite_years_df_exploded.insert(0, \"elite_id\", range(1, len(elite_years_df_exploded) + 1))\n",
        "\n",
        "elite_years_df_exploded\n",
        "\n",
        "elite_years_df_exploded['elite'].value_counts()\n",
        "\n",
        "elite_years_df_exploded['elite_years'] = pd.to_numeric(elite_years_df_exploded['elite'])\n",
        "\n",
        "elite_years_df_exploded.drop('elite',axis=1,inplace=True)\n",
        "\n",
        "user_df.drop('elite',axis=1,inplace=True)\n",
        "\n",
        "business_df.drop('categories', axis=1,inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts7gKuvoyQJz"
      },
      "outputs": [],
      "source": [
        "# %% [code]\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"badm-554-mini-project-1-group-3.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1rrTIHXoZD8P1y8tPE6mrkn4_T1KFTsiv\n",
        "\"\"\"\n",
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "\n",
        "#linked to user and business table through user_id and business_id\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# 讀取 Business JSON\n",
        "data_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_business.json\")\n",
        "data = []\n",
        "for line in data_file:\n",
        "    data.append(json.loads(line))\n",
        "business_df = pd.DataFrame(data)\n",
        "data_file.close()\n",
        "\n",
        "# ✅ 正確保留 is_open，不要轉錯（Yelp 原本就是 0/1）\n",
        "business_df['is_open'] = business_df['is_open'].astype(int)\n",
        "\n",
        "# ✅ 展開 hours\n",
        "business_df = pd.concat(\n",
        "    [business_df.drop(columns=['hours']),\n",
        "     pd.json_normalize(business_df['hours'])],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# ✅ Hours 欄位重新命名\n",
        "business_df = business_df.rename(columns={\n",
        "    'Monday':'monday_hours',\n",
        "    'Tuesday':'tuesday_hours',\n",
        "    'Wednesday':'wednesday_hours',\n",
        "    'Thursday':'thursday_hours',\n",
        "    'Friday':'friday_hours',\n",
        "    'Saturday':'saturday_hours',\n",
        "    'Sunday':'sunday_hours'\n",
        "})\n",
        "\n",
        "# ✅ 移除 attributes，之後會拆到 attribute 表\n",
        "business_df.drop(columns=['attributes'], inplace=True)\n",
        "\n",
        "# ✅ 最終欄位（只保留需要的 16 欄）\n",
        "business_df = business_df[['business_id','name','address','city','state','postal_code',\n",
        "                           'latitude','longitude','is_open',\n",
        "                           'monday_hours','tuesday_hours','wednesday_hours',\n",
        "                           'thursday_hours','friday_hours','saturday_hours','sunday_hours']]\n",
        "\n",
        "# ✅ 先把 city 可能的 NaN 補成空字串，避免字串操作報錯\n",
        "business_df['city'] = business_df['city'].fillna('')\n",
        "\n",
        "# ✅ 標準化 city：去掉 . 與空白、trim、轉小寫\n",
        "#    例： \"Santa Barbara\"、\"Santa  Barbara.\"、\"Santa.Barbara\" → \"santabarbara\"\n",
        "business_df['city'] = (\n",
        "    business_df['city']\n",
        "      .astype(str)\n",
        "      .str.strip()\n",
        "      .str.replace(r\"[.\\s]+\", \"\", regex=True)\n",
        "      .str.lower()\n",
        ")\n",
        "\n",
        "# ✅ 其他欄位空值補齊（不影響 city 的正規化）\n",
        "business_df = business_df.fillna(\"\")\n",
        "\n",
        "print(\"✅ business_df rows:\", len(business_df))\n",
        "display(business_df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXNUCGDYzPuq"
      },
      "source": [
        "Exported as parquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1DU72nczT4G"
      },
      "outputs": [],
      "source": [
        "business_df.to_parquet(\"business.parquet\")\n",
        "business_categories_df_exploded.to_parquet(\"category.parquet\")\n",
        "business_attributes.to_parquet(\"attribute.parquet\")\n",
        "checkin_df_exploded.to_parquet(\"checkin.parquet\")\n",
        "tip_df_cleaned.to_parquet(\"tip.parquet\")\n",
        "user_df.to_parquet(\"user.parquet\")\n",
        "elite_years_df_exploded.to_parquet(\"elite.parquet\")\n",
        "review_df.to_parquet(\"review.parquet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD52Own6zfpg"
      },
      "source": [
        "Upload to Azure Blob Storage + COPY INTO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPtfk0Gzz1Tm"
      },
      "source": [
        "Built Data Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ4xvoNoz-sL"
      },
      "outputs": [],
      "source": [
        "-- 1. category\n",
        "IF OBJECT_ID('tb_category', 'U') IS NOT NULL DROP TABLE tb_category;\n",
        "CREATE TABLE tb_category (\n",
        "    category_id NVARCHAR(50) PRIMARY KEY,\n",
        "    business_id NVARCHAR(50),\n",
        "    categories NVARCHAR(4000)\n",
        ");\n",
        "\n",
        "-- 2. attribute\n",
        "IF OBJECT_ID('tb_attribute', 'U') IS NOT NULL DROP TABLE tb_attribute;\n",
        "CREATE TABLE tb_attribute (\n",
        "    attribute_id NVARCHAR(50) PRIMARY KEY,\n",
        "    business_id NVARCHAR(50),\n",
        "    attribute_name NVARCHAR(255),\n",
        "    attribute_value NVARCHAR(255)\n",
        ");\n",
        "\n",
        "-- 3. checkin\n",
        "IF OBJECT_ID('tb_checkin', 'U') IS NOT NULL DROP TABLE tb_checkin;\n",
        "CREATE TABLE tb_checkin (\n",
        "    checkin_id NVARCHAR(50) PRIMARY KEY,\n",
        "    business_id NVARCHAR(50),\n",
        "    date DATETIME\n",
        ");\n",
        "\n",
        "-- 4. elite\n",
        "IF OBJECT_ID('tb_elite', 'U') IS NOT NULL DROP TABLE tb_elite;\n",
        "CREATE TABLE tb_elite (\n",
        "    elite_id NVARCHAR(50) PRIMARY KEY,\n",
        "    user_id NVARCHAR(50),\n",
        "    elite_years NVARCHAR(255)\n",
        ");\n",
        "\n",
        "-- 5. tip\n",
        "IF OBJECT_ID('tb_tip', 'U') IS NOT NULL DROP TABLE tb_tip;\n",
        "CREATE TABLE tb_tip (\n",
        "    tip_id NVARCHAR(50) PRIMARY KEY,\n",
        "    user_id NVARCHAR(50),\n",
        "    business_id NVARCHAR(50),\n",
        "    text NVARCHAR(MAX),\n",
        "    date DATETIME\n",
        ");\n",
        "\n",
        "-- 6. user\n",
        "IF OBJECT_ID('tb_user', 'U') IS NOT NULL DROP TABLE tb_user;\n",
        "CREATE TABLE tb_user (\n",
        "    user_id NVARCHAR(50) PRIMARY KEY,\n",
        "    name NVARCHAR(255),\n",
        "    yelping_since DATETIME,\n",
        "    useful INT,\n",
        "    funny INT,\n",
        "    cool INT,\n",
        "    friends NVARCHAR(MAX),\n",
        "    fans INT,\n",
        "    compliment_hot INT,\n",
        "    compliment_more INT,\n",
        "    compliment_profile INT,\n",
        "    compliment_cute INT,\n",
        "    compliment_list INT,\n",
        "    compliment_note INT,\n",
        "    compliment_plain INT,\n",
        "    compliment_cool INT,\n",
        "    compliment_funny INT,\n",
        "    compliment_writer INT,\n",
        "    compliment_photos INT\n",
        ");\n",
        "\n",
        "-- 7. review\n",
        "IF OBJECT_ID('tb_review', 'U') IS NOT NULL DROP TABLE tb_review;\n",
        "CREATE TABLE tb_review (\n",
        "    review_id NVARCHAR(50) PRIMARY KEY,\n",
        "    user_id NVARCHAR(50),\n",
        "    business_id NVARCHAR(50),\n",
        "    stars INT,\n",
        "    useful INT,\n",
        "    funny INT,\n",
        "    cool INT,\n",
        "    text NVARCHAR(MAX),\n",
        "    date DATETIME,\n",
        "    time NVARCHAR(50)\n",
        ");\n",
        "\n",
        "-- 8. business\n",
        "IF OBJECT_ID('tb_business', 'U') IS NOT NULL DROP TABLE tb_review;\n",
        "CREATE TABLE tb_business (\n",
        "    business_id NVARCHAR(50) PRIMARY KEY,\n",
        "    name NVARCHAR(255),\n",
        "    address NVARCHAR(255),\n",
        "    city NVARCHAR(100),\n",
        "    state NVARCHAR(50),\n",
        "    postal_code NVARCHAR(20),\n",
        "    latitude FLOAT,\n",
        "    longitude FLOAT,\n",
        "    is_open BIT,\n",
        "    monday_hours NVARCHAR(100),\n",
        "    tuesday_hours NVARCHAR(100),\n",
        "    wednesday_hours NVARCHAR(100),\n",
        "    thursday_hours NVARCHAR(100),\n",
        "    friday_hours NVARCHAR(100),\n",
        "    saturday_hours NVARCHAR(100),\n",
        "    sunday_hours NVARCHAR(100)\n",
        "\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB4-2XHX0X-S"
      },
      "source": [
        "Importing Azure SQL database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rA3_YJP0gXC"
      },
      "outputs": [],
      "source": [
        "#The database login information has been removed for security purposes\n",
        "DECLARE @sastoken NVARCHAR(MAX) =\n",
        "'';\n",
        "\n",
        "COPY INTO tb_category\n",
        "FROM 'https://yelpallen.blob.core.windows.net/yelp/category.parquet' + @sastoken\n",
        "WITH (FILE_TYPE = 'PARQUET');\n",
        "\n",
        "COPY INTO tb_attribute\n",
        "FROM 'https://yelpallen.blob.core.windows.net/yelp/attribute.parquet' + @sastoken\n",
        "WITH (FILE_TYPE = 'PARQUET');\n",
        "\n",
        "COPY INTO tb_checkin\n",
        "FROM 'https://yelpallen.blob.core.windows.net/yelp/checkin.parquet' + @sastoken\n",
        "WITH (FILE_TYPE = 'PARQUET');\n",
        "\n",
        "COPY INTO tb_elite\n",
        "FROM 'https://yelpallen.blob.core.windows.net/yelp/elite.parquet' + @sastoken\n",
        "WITH (FILE_TYPE = 'PARQUET');\n",
        "\n",
        "COPY INTO tb_tip\n",
        "FROM 'https://yelpallen.blob.core.windows.net/yelp/tip.parquet' + @sastoken\n",
        "WITH (FILE_TYPE = 'PARQUET');\n",
        "\n",
        "COPY INTO tb_user\n",
        "FROM 'https://yelpallen.blob.core.windows.net/yelp/user.parquet' + @sastoken\n",
        "WITH (FILE_TYPE = 'PARQUET');\n",
        "\n",
        "COPY INTO tb_review\n",
        "FROM 'https://yelpallen.blob.core.windows.net/yelp/review.parquet' + @sastoken\n",
        "WITH (FILE_TYPE = 'PARQUET');\n",
        "\n",
        "COPY INTO tb_business\n",
        "FROM 'https://yelpallen.blob.core.windows.net/yelp/business.parquet' + @sastoken\n",
        "WITH (FILE_TYPE = 'PARQUET');"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
